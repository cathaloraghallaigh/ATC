{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6110b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted tagged .txt files and all.csv, kept Dataset.csv and .pdb files.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Iterable\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Prefix used for temporary .txt files (only these are deleted)\n",
    "TAG = \"AAFEAT_x9k42_\"\n",
    "\n",
    "# Header row for the combined CSV (no \"Pocket Score\")\n",
    "HEADER_TITLE = (\n",
    "    \"Protein\\tCyclical\\tDrug Score\\tNumber of alpha spheres\\t\"\n",
    "    \"Mean alpha-sphere radius\\tMean alpha-sphere Solvent Acc.\\tMean B-factor of pocket residues\\t\"\n",
    "    \"Hydrophobicity Score\\tPolarity Score\\tAmino Acid based volume Score\\tPocket volume (Monte Carlo)\\t\"\n",
    "    \"Pocket volume (convex hull)\\tCharge Score\\tLocal hydrophobic density Score\\tNumber of apolar alpha sphere\\t\"\n",
    "    \"Proportion of apolar alpha sphere\\tAS Sequence\"\n",
    ")\n",
    "\n",
    "# Amino-acid groups\n",
    "AA_ORDER = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "NON_POLAR = set(list(\"GAVLIMFP\"))\n",
    "POLAR_UNCHARGED = set([\"S\", \"T\", \"N\", \"Q\", \"Y\", \"C\", \"W\"]) \n",
    "CHARGED_POS = set(list(\"RHK\"))\n",
    "CHARGED_NEG = set(list(\"DE\"))\n",
    "IONISABLE = set([\"D\", \"E\", \"H\", \"C\", \"Y\", \"K\", \"R\"]) \n",
    "AROMATIC = set([\"F\", \"W\", \"Y\", \"H\"]) \n",
    "HYDROPHOBIC = set([\"F\", \"W\", \"Y\", \"H\", \"K\", \"M\", \"T\", \"L\", \"I\", \"V\", \"C\", \"G\", \"A\"]) \n",
    "SMALL = set([\"A\", \"C\", \"S\", \"G\", \"V\", \"T\", \"N\", \"D\", \"P\"]) \n",
    "TINY = set([\"A\", \"C\", \"S\", \"G\"]) \n",
    "\n",
    "# Labels appended to Dataset.csv (fixed order and spelling)\n",
    "APPEND_LABELS = [\n",
    "    \"Number of residues\",\n",
    "    \"Ionisable groups\",\n",
    "    \"Polar\",\n",
    "    \"Non-polar\",\n",
    "    \"Charged\",\n",
    "    \"Positive charge\",\n",
    "    \"Negative charge\",\n",
    "    \"Pos-neg charge ratio\",\n",
    "    \"Uncharged\",\n",
    "    \"Aromatic\",\n",
    "    \"Hydrophobic\",\n",
    "    \"Small\",\n",
    "    \"tiny\",\n",
    "]\n",
    "\n",
    "# 3-letter to 1-letter amino acid mapping\n",
    "MAP_3TO1 = {\n",
    "    \"ALA\":\"A\",\"CYS\":\"C\",\"ASP\":\"D\",\"GLU\":\"E\",\"PHE\":\"F\",\"GLY\":\"G\",\"HIS\":\"H\",\n",
    "    \"HID\":\"H\",\"HIE\":\"H\",\"HIP\":\"H\",\"ILE\":\"I\",\"LYS\":\"K\",\"LEU\":\"L\",\"MET\":\"M\",\n",
    "    \"ASN\":\"N\",\"PRO\":\"P\",\"GLN\":\"Q\",\"ARG\":\"R\",\"SER\":\"S\",\"THR\":\"T\",\"VAL\":\"V\",\n",
    "    \"TRP\":\"W\",\"TYR\":\"Y\",\"MSE\":\"X\"\n",
    "}\n",
    "\n",
    "_last_number_re = re.compile(r'([-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)\\s*$')\n",
    "_cyc_pat = re.compile(r'(?:^|[_\\-])([LC])(?:[_\\-]|$)', re.IGNORECASE)\n",
    "\n",
    "# File helpers\n",
    "\n",
    "def read_text_lines(p: Path) -> List[str]:\n",
    "    with p.open('r', encoding='utf-8', errors='ignore') as fh:\n",
    "        return fh.readlines()\n",
    "\n",
    "\n",
    "def write_lines(p: Path, lines: Iterable[str]) -> None:\n",
    "    with p.open('w', encoding='utf-8', newline='') as fh:\n",
    "        for ln in lines:\n",
    "            if not ln.endswith('\\n'):\n",
    "                ln += '\\n'\n",
    "            fh.write(ln)\n",
    "\n",
    "# Sequence helpers\n",
    "\n",
    "def normalize_seq(seq: str) -> str:\n",
    "    return ''.join([ch for ch in seq.upper() if ch.isalpha()])\n",
    "\n",
    "\n",
    "def count_residues(seq: str) -> Dict[str, int]:\n",
    "    counts = {aa: 0 for aa in AA_ORDER}\n",
    "    for ch in seq:\n",
    "        if ch in counts:\n",
    "            counts[ch] += 1\n",
    "    return counts\n",
    "\n",
    "# Compute residue-based features\n",
    "\n",
    "def feature_counts(seq: str) -> Dict[str, float]:\n",
    "    s = normalize_seq(seq)\n",
    "    n = len(s)\n",
    "    c = count_residues(s)\n",
    "    nonpolar = sum(c[a] for a in NON_POLAR)\n",
    "    polar = sum(c[a] for a in POLAR_UNCHARGED)\n",
    "    charged_pos = sum(c[a] for a in CHARGED_POS)\n",
    "    charged_neg = sum(c[a] for a in CHARGED_NEG)\n",
    "    charged = charged_pos + charged_neg\n",
    "    uncharged = n - charged\n",
    "    ionisable = sum(c[a] for a in IONISABLE)\n",
    "    aromatic = sum(c[a] for a in AROMATIC)\n",
    "    hydrophobic = sum(c[a] for a in HYDROPHOBIC)\n",
    "    small = sum(c[a] for a in SMALL)\n",
    "    tiny = sum(c[a] for a in TINY)\n",
    "    pos_neg_ratio = (charged_pos / charged_neg) if charged_neg != 0 else 0\n",
    "    return {\n",
    "        \"Number of residues\": n,\n",
    "        \"Ionisable groups\": ionisable,\n",
    "        \"Polar\": polar,\n",
    "        \"Non-polar\": nonpolar,\n",
    "        \"Charged\": charged,\n",
    "        \"Positive charge\": charged_pos,\n",
    "        \"Negative charge\": charged_neg,\n",
    "        \"Pos-neg charge ratio\": round(pos_neg_ratio, 3),\n",
    "        \"Uncharged\": uncharged,\n",
    "        \"Aromatic\": aromatic,\n",
    "        \"Hydrophobic\": hydrophobic,\n",
    "        \"Small\": small,\n",
    "        \"tiny\": tiny,\n",
    "    }\n",
    "\n",
    "# Build sequence of unique residues from ATOM records using fixed PDB columns\n",
    "\n",
    "def pdb_unique_res_sequence(pdb_path: Path) -> str:\n",
    "    seen = set()\n",
    "    order_resnames: List[str] = []\n",
    "    for line in read_text_lines(pdb_path):\n",
    "        if not line.startswith(\"ATOM\"):\n",
    "            continue\n",
    "        resname = line[17:20].strip().upper()\n",
    "        chainID = line[21:22]\n",
    "        resSeq  = line[22:26].strip()\n",
    "        iCode   = line[26:27]\n",
    "        key = (chainID, resSeq, iCode)\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            order_resnames.append(resname)\n",
    "    return ''.join(MAP_3TO1.get(r, 'X') for r in order_resnames)\n",
    "\n",
    "# Extract last numeric token from header lines 6â€“20 (15 total)\n",
    "\n",
    "def extract_last_fields_block(pdb_path: Path) -> List[str]:\n",
    "    lines = read_text_lines(pdb_path)\n",
    "    block = lines[5:20]\n",
    "    vals: List[str] = []\n",
    "    for ln in block:\n",
    "        m = _last_number_re.search(ln)\n",
    "        if m:\n",
    "            vals.append(m.group(1))\n",
    "        else:\n",
    "            toks = ln.strip().split()\n",
    "            vals.append(toks[-1] if toks else \"\")\n",
    "    if len(vals) < 15:\n",
    "        vals += [\"\"] * (15 - len(vals))\n",
    "    elif len(vals) > 15:\n",
    "        vals = vals[:15]\n",
    "    return vals\n",
    "\n",
    "# Create a tagged .txt file per .pdb\n",
    "\n",
    "def stage1_make_txts():\n",
    "    for pdb in sorted(Path('.').glob('*.pdb')):\n",
    "        base = pdb.stem\n",
    "        metrics = extract_last_fields_block(pdb)\n",
    "        seq = pdb_unique_res_sequence(pdb)\n",
    "        fields = [base, \"\"] + metrics + [seq]\n",
    "        out_txt = Path(f\"{TAG}{base}.txt\")\n",
    "        write_lines(out_txt, fields)\n",
    "\n",
    "# Detect L/C tag from names. Returns \"0\" (linear), \"1\" (cyclic), or \"\" if unknown.\n",
    "\n",
    "def _detect_cyc_from_names(txt_stem: str, protein_name: str) -> str:\n",
    "    for candidate in (protein_name, txt_stem):\n",
    "        m = _cyc_pat.search(candidate)\n",
    "        if m:\n",
    "            return \"0\" if m.group(1).upper() == \"L\" else \"1\"\n",
    "    return \"\"\n",
    "\n",
    "# Combine tagged .txt files into all.csv and fill Cyclical\n",
    "\n",
    "def stage2_combine_to_csv(all_csv: Path = Path('all.csv')):\n",
    "    header = HEADER_TITLE.replace('\\t', ',')\n",
    "    with all_csv.open('w', encoding='utf-8', newline='') as fh:\n",
    "        fh.write(header + '\\n')\n",
    "        for txt in sorted(Path('.').glob(f'{TAG}*.txt')):\n",
    "            values = [ln.strip() for ln in read_text_lines(txt) if ln.strip()]\n",
    "            # values[0]=Protein, values[1]=Cyclical, values[2..16]=metrics, values[17]=seq\n",
    "            if len(values) < 17:\n",
    "                values += [\"\"] * (17 - len(values))\n",
    "            elif len(values) > 17:\n",
    "                values = values[:17]\n",
    "\n",
    "            txt_stem = Path(txt).stem\n",
    "            protein_name = values[0]\n",
    "\n",
    "            cyc_val = _detect_cyc_from_names(txt_stem, protein_name)\n",
    "            values[1] = cyc_val\n",
    "\n",
    "            fh.write(','.join(values) + '\\n')\n",
    "\n",
    "# Read all.csv, compute AA features and per-AA counts, write Dataset.csv\n",
    "\n",
    "def stage3_append_features(in_csv: Path = Path('all.csv'), out_csv: Path = Path('Dataset.csv')):\n",
    "    AA_COUNT_LABELS = [\n",
    "        (\"Glycine - G\", \"G\"),\n",
    "        (\"Alanine - A\", \"A\"),\n",
    "        (\"Leucine - L\", \"L\"),\n",
    "        (\"Methionine - M\", \"M\"),\n",
    "        (\"Phenylalanine - F\", \"F\"),\n",
    "        (\"Tryptophan - W\", \"W\"),\n",
    "        (\"Lysine - K\", \"K\"),\n",
    "        (\"Glutamine - Q\", \"Q\"),\n",
    "        (\"Glutamic Acid - E\", \"E\"),\n",
    "        (\"Serine - S\", \"S\"),\n",
    "        (\"Proline - P\", \"P\"),\n",
    "        (\"Valine - V\", \"V\"),\n",
    "        (\"Isoleucine - I\", \"I\"),\n",
    "        (\"Cysteine - C\", \"C\"),\n",
    "        (\"Tyrosine - Y\", \"Y\"),\n",
    "        (\"Histidine - H\", \"H\"),\n",
    "        (\"Arginine - R\", \"R\"),\n",
    "        (\"Asparagine - N\", \"N\"),\n",
    "        (\"Aspartic Acid - D\", \"D\"),\n",
    "        (\"Threonine - T\", \"T\"),\n",
    "    ]\n",
    "\n",
    "    with in_csv.open('r', encoding='utf-8', newline='') as fh:\n",
    "        reader = csv.DictReader(fh)\n",
    "        fields_in = reader.fieldnames or []\n",
    "\n",
    "        drop_cols = {\"Mean B-factor of pocket residues\", \"AS Sequence\"}\n",
    "        fields_kept = [f for f in fields_in if f not in drop_cols]\n",
    "\n",
    "        aa_count_fields = [lbl for (lbl, _) in AA_COUNT_LABELS if lbl not in fields_kept]\n",
    "        append_feature_fields = [c for c in APPEND_LABELS if c not in fields_kept and c not in aa_count_fields]\n",
    "        fields_out = fields_kept + aa_count_fields + append_feature_fields\n",
    "\n",
    "        with out_csv.open('w', encoding='utf-8', newline='') as outfh:\n",
    "            writer = csv.DictWriter(outfh, fieldnames=fields_out, extrasaction='ignore')\n",
    "            writer.writeheader()\n",
    "            for row in reader:\n",
    "                seq = row.get('AS Sequence', '')\n",
    "                norm_seq = normalize_seq(seq)\n",
    "\n",
    "                cdict = count_residues(norm_seq)\n",
    "                aa_counts = {lbl: cdict.get(aa, 0) for (lbl, aa) in AA_COUNT_LABELS}\n",
    "\n",
    "                feats = feature_counts(seq)\n",
    "\n",
    "                out_row = {k: v for k, v in row.items() if k in fields_kept}\n",
    "                out_row.update(aa_counts)\n",
    "                for k in append_feature_fields:\n",
    "                    out_row[k] = feats.get(k, 0)\n",
    "\n",
    "                writer.writerow(out_row)\n",
    "\n",
    "# Run stages\n",
    "stage1_make_txts()\n",
    "stage2_combine_to_csv()\n",
    "stage3_append_features()\n",
    "\n",
    "# Cleanup tagged .txt files and all.csv; keep Dataset.csv and .pdb files\n",
    "for txt in Path('.').glob(f'{TAG}*.txt'):\n",
    "    try:\n",
    "        txt.unlink()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "all_csv = Path('all.csv')\n",
    "if all_csv.exists():\n",
    "    try:\n",
    "        all_csv.unlink()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"Deleted tagged .txt files and all.csv, kept Dataset.csv and .pdb files.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
