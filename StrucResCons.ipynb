{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e0f9d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies for the script\n",
    "!pip install --quiet numpy pandas matplotlib logomaker biopython\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import logomaker\n",
    "from collections import defaultdict\n",
    "from Bio.Data import IUPACData\n",
    "\n",
    "# =============================================================\n",
    "# 1. Imports and configuration\n",
    "# =============================================================\n",
    "INPUT_FILE = \"2ongcealigned.cif\"  # All proteins should be aligned in a single .cif file\n",
    "PROTEIN_OF_INTEREST = \"2ONG_C\".strip().upper()\n",
    "ERROR_THRESHOLD = 4.0\n",
    "HARDEST_FIRST = True\n",
    "DELTA = \"Δ\"\n",
    "FREQ_CUTOFF = 0.15\n",
    "\n",
    "# =============================================================\n",
    "# 1b. Output directory setup\n",
    "# =============================================================\n",
    "OUTPUT_DIR = \"StructuralAlignmentOut\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Normalized output filenames\n",
    "OUTPUT_ASSIGNMENTS = os.path.join(OUTPUT_DIR, \"residue_assignments.csv\")\n",
    "# Δ-frequency summary gets a stable, readable name\n",
    "DELTA_SUMMARY_OUT = os.path.join(\n",
    "    OUTPUT_DIR,\n",
    "    f\"group_delta_summary_freq_ge_{str(FREQ_CUTOFF).replace('.', 'p')}.csv\"\n",
    ")\n",
    "\n",
    "# =============================================================\n",
    "# 2. Grouping options\n",
    "# =============================================================\n",
    "# GROUP_MODE:\n",
    "#   - \"grouped\": use GROUP_REGEX to extract a token from the protein id, then map via GROUP_SPEC\n",
    "#   - \"all\":     treat all proteins as one group \"All\"\n",
    "GROUP_MODE = \"grouped\"  # or \"all\"\n",
    "GROUP_REGEX = r\".*_([A-Za-z]+)$\"   # captures trailing token after underscore, e.g. 2ONG_C -> \"C\"\n",
    "\n",
    "# Edit this to rename or change how many groups you expect\n",
    "GROUP_SPEC = [\n",
    "    (\"L\", \"Linear\"),      # token \"L\" becomes group \"Linear\"\n",
    "    (\"C\", \"Cyclical\"),    # token \"C\" becomes group \"Cyclical\"\n",
    "]\n",
    "\n",
    "# Derived mappings and validations\n",
    "REGEX_MAP = {tok: name for tok, name in GROUP_SPEC}\n",
    "EXPECTED_N_GROUPS = len(GROUP_SPEC)   # set None to skip validation\n",
    "EXPECTED_TOKENS = {tok for tok, _ in GROUP_SPEC}\n",
    "EXPECTED_LABELS = [name for _, name in GROUP_SPEC]\n",
    "\n",
    "# TARGET_MODE:\n",
    "#   - \"manual\": use MANUAL_RESIDUES below\n",
    "#   - \"all\":    use all residue numbers present in the reference protein\n",
    "TARGET_MODE = \"manual\"  # or \"all\"\n",
    "\n",
    "# Manually specified residues (used when TARGET_MODE = \"manual\")\n",
    "MANUAL_RESIDUES = [\n",
    "    63, 315, 324, 345, 348, 349, 352, 353, 356, 427, 430, 452, 453, 454,\n",
    "    458, 492, 493, 496, 499, 500, 502, 503, 504, 507, 509, 512, 573,\n",
    "    577, 578, 579, 581, 582\n",
    "]\n",
    "\n",
    "# 3-letter to single letter AA mapping\n",
    "AA3_TO_1 = {k.upper(): v for k, v in IUPACData.protein_letters_3to1.items()}\n",
    "AA3_TO_1.update({'SEC': 'U', 'PYL': 'O'})  # Include uncommon amino acids\n",
    "\n",
    "# =============================================================\n",
    "# 3. Plot configuration (fonts + logo colour + chunking readability)\n",
    "#    All size values specified in centimeters (cm)\n",
    "# =============================================================\n",
    "# Fonts\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['font.serif'] = ['Times New Roman', 'Times', 'DejaVu Serif', 'serif']\n",
    "\n",
    "# Sequence-logo colour scheme (logomaker built-ins: 'chemistry', 'hydrophobicity', 'charge', 'monochrome')\n",
    "LOGO_COLOR_SCHEME = 'chemistry'\n",
    "\n",
    "# Readability of sequence logos (units: cm)\n",
    "MAX_POSITIONS_PER_FIG = 40   # alignment positions per logo figure (chunk size)\n",
    "MIN_GLOBAL_FREQ = 0.02       # minimum AA frequency to appear in logo \n",
    "WIDTH_PER_POS_CM = 0.7       # cm added per position to figure width\n",
    "BASE_WIDTH_CM = 5.0          # base figure width (cm)\n",
    "FIG_HEIGHT_CM = 10.0         # figure height (cm)\n",
    "DPI = 400                    # saved figure resolution\n",
    "XTICK_LABEL_ROT = 90         # x-axis tick rotation (degrees)\n",
    "\n",
    "# Conversion helper: centimeters to inches for Matplotlib\n",
    "CM_TO_IN = 1.0 / 2.54\n",
    "\n",
    "# Save or not save PNGs of sequence logos\n",
    "SAVE_LOGO_PNG = False\n",
    "\n",
    "# =============================================================\n",
    "# 3b. Quick group preview (headers only)\n",
    "# =============================================================\n",
    "\n",
    "def _scan_protein_ids(path: str):\n",
    "    prots = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"data_\"):\n",
    "                prots.append(line[len(\"data_\"):].strip().upper())\n",
    "    return prots\n",
    "\n",
    "\n",
    "def _group_label_from_id(pid: str) -> str:\n",
    "    if GROUP_MODE == \"all\":\n",
    "        return \"All\"\n",
    "    m = re.match(GROUP_REGEX, pid)\n",
    "    if m:\n",
    "        token = m.group(1)\n",
    "        return REGEX_MAP.get(token, token)\n",
    "    return \"Unassigned\"\n",
    "\n",
    "# Run the preview\n",
    "_all_ids = _scan_protein_ids(INPUT_FILE)\n",
    "print(\"\\n=== Group Preview (from file headers only) ===\")\n",
    "if not _all_ids:\n",
    "    print(\"No 'data_' blocks found in the input file.\")\n",
    "else:\n",
    "    if GROUP_MODE == \"all\":\n",
    "        print(f\"GROUP_MODE='all' -> single group 'All' (n={len(_all_ids)})\")\n",
    "        for p in sorted(_all_ids):\n",
    "            print(f\"  - {p}\")\n",
    "    else:\n",
    "        _preview_groups = {}\n",
    "        for pid in _all_ids:\n",
    "            g = _group_label_from_id(pid)\n",
    "            _preview_groups.setdefault(g, []).append(pid)\n",
    "\n",
    "        named = [g for g in _preview_groups if g != \"Unassigned\"]\n",
    "        if EXPECTED_N_GROUPS is not None:\n",
    "            if len(named) != EXPECTED_N_GROUPS:\n",
    "                print(f\"[WARN] Expected {EXPECTED_N_GROUPS} groups, found {len(named)}: {sorted(named)}\")\n",
    "\n",
    "        total_named = sum(len(_preview_groups[g]) for g in named)\n",
    "        print(f\"Total proteins: {len(_all_ids)} | Grouped (named): {total_named}\")\n",
    "        for g in sorted(_preview_groups):\n",
    "            members = sorted(_preview_groups[g])\n",
    "            print(f\"\\nGroup: {g}  (n={len(members)})\")\n",
    "            for m in members:\n",
    "                print(f\"  - {m}\")\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 4. Function: extract alpha carbons\n",
    "# =============================================================\n",
    "\n",
    "def extract_alpha_carbons(path: str):\n",
    "    \"\"\"Parse CIF/PDB-like alignment file and extract CA coordinates.\"\"\"\n",
    "    out = []\n",
    "    current = None\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"data_\"):\n",
    "                current = line[len(\"data_\"):].strip().upper()\n",
    "                continue\n",
    "            if not current:\n",
    "                continue\n",
    "            if line.startswith(\"ATOM\") and \" CA \" in line:\n",
    "                fields = re.split(r\"\\s+\", line.strip())\n",
    "                try:\n",
    "                    resname_3 = fields[5]\n",
    "                    resnum = int(fields[8])\n",
    "                    x, y, z = float(fields[10]), float(fields[11]), float(fields[12])\n",
    "                except Exception:\n",
    "                    continue\n",
    "                aa1 = AA3_TO_1.get(resname_3.upper(), \"-\")\n",
    "                out.append((current, resnum, aa1, np.array([x, y, z], float)))\n",
    "    return out\n",
    "\n",
    "# =============================================================\n",
    "# 5. Extract and prepare reference data (+ choose target positions)\n",
    "# =============================================================\n",
    "alpha_carbons = extract_alpha_carbons(INPUT_FILE)\n",
    "\n",
    "specified_residues = {rnum: aa for pid, rnum, aa, _ in alpha_carbons if pid == PROTEIN_OF_INTEREST}\n",
    "\n",
    "# Decide the target residue set based on TARGET_MODE\n",
    "if TARGET_MODE == \"all\":\n",
    "    TARGET_POSITIONS = sorted({rnum for pid, rnum, aa, _ in alpha_carbons if pid == PROTEIN_OF_INTEREST})\n",
    "else:\n",
    "    TARGET_POSITIONS = list(MANUAL_RESIDUES)\n",
    "\n",
    "# Collect chosen target CA coords from reference\n",
    "target_coords = [\n",
    "    (rnum, aa, coords)\n",
    "    for pid, rnum, aa, coords in alpha_carbons\n",
    "    if pid == PROTEIN_OF_INTEREST and rnum in TARGET_POSITIONS\n",
    "]\n",
    "\n",
    "ref_resname = {rnum: aa for rnum, aa, _ in target_coords}\n",
    "\n",
    "# =============================================================\n",
    "# 6. Group residues by protein (excluding reference protein)\n",
    "# =============================================================\n",
    "by_protein = defaultdict(list)\n",
    "for pid, rnum, aa, xyz in alpha_carbons:\n",
    "    if pid != PROTEIN_OF_INTEREST:\n",
    "        by_protein[pid].append((rnum, aa, xyz))\n",
    "\n",
    "assign_rows = []\n",
    "\n",
    "# =============================================================\n",
    "# 7. Residue mapping and assignment (one-to-one per protein, with error checking)\n",
    "# =============================================================\n",
    "for pid, residues in by_protein.items():\n",
    "    candidates, stats = {}, {}\n",
    "    for t_rnum, _, t_xyz in target_coords:\n",
    "        pairs = [(float(np.linalg.norm(t_xyz - xyz)), rnum, aa) for rnum, aa, xyz in residues]\n",
    "        pairs.sort(key=lambda x: (x[0], x[1]))\n",
    "        candidates[t_rnum] = pairs\n",
    "        within = [p for p in pairs if p[0] <= ERROR_THRESHOLD]\n",
    "        min_d = pairs[0][0] if pairs else float('inf')\n",
    "        second = pairs[1][0] if len(pairs) > 1 else float('inf')\n",
    "        stats[t_rnum] = {'num_in': len(within), 'min_d': min_d, 'ambiguity': second - min_d}\n",
    "\n",
    "    order = sorted([t[0] for t in target_coords],\n",
    "                   key=(lambda r: (stats[r]['num_in'], stats[r]['ambiguity'], stats[r]['min_d'])) if HARDEST_FIRST\n",
    "                        else (lambda r: stats[r]['min_d']))\n",
    "\n",
    "    owner, assign = {}, {}\n",
    "\n",
    "    # initialize per-target diagnostic row\n",
    "    for t_rnum in [t[0] for t in target_coords]:\n",
    "        best = candidates[t_rnum][0] if candidates[t_rnum] else (float('inf'), '-', '-')\n",
    "        assign[t_rnum] = {\n",
    "            'Target Residue Number': t_rnum,\n",
    "            'Target Residue Name': ref_resname[t_rnum],\n",
    "            'Protein': pid,\n",
    "            'Residue Name': '-',\n",
    "            'Residue Number': '-',\n",
    "            'Distance': best[0],\n",
    "            'Status': 'no_unused_within_threshold',\n",
    "            'Nearest Residue Name': best[2],\n",
    "            'Nearest Residue Number': best[1],\n",
    "            'Nearest Distance': best[0],\n",
    "        }\n",
    "\n",
    "    def set_assign(t_num, rnum, aa, dist):\n",
    "        owner[rnum] = (t_num, dist)\n",
    "        assign[t_num] = {\n",
    "            'Target Residue Number': t_num,\n",
    "            'Target Residue Name': ref_resname[t_num],\n",
    "            'Protein': pid,\n",
    "            'Residue Name': aa,\n",
    "            'Residue Number': rnum,\n",
    "            'Distance': dist,\n",
    "            'Status': 'assigned',\n",
    "        }\n",
    "\n",
    "    def reassign_displaced(t_num):\n",
    "        for d2, r2, aa2 in candidates[t_num]:\n",
    "            if d2 <= ERROR_THRESHOLD and r2 not in owner:\n",
    "                set_assign(t_num, r2, aa2, d2)\n",
    "                return True\n",
    "        assign[t_num]['Status'] = 'lost_swap_no_alt'\n",
    "        return False\n",
    "\n",
    "    for t_rnum in order:\n",
    "        for d, rnum, aa in candidates[t_rnum]:\n",
    "            if d > ERROR_THRESHOLD:\n",
    "                break\n",
    "            cur = owner.get(rnum)\n",
    "            if cur is None:\n",
    "                set_assign(t_rnum, rnum, aa, d)\n",
    "                break\n",
    "            prev_t, prev_d = cur\n",
    "            if d < prev_d:\n",
    "                set_assign(t_rnum, rnum, aa, d)\n",
    "                if not reassign_displaced(prev_t):\n",
    "                    pass\n",
    "                break\n",
    "\n",
    "    for t_rnum in [t[0] for t in target_coords]:\n",
    "        assign_rows.append(assign[t_rnum])\n",
    "\n",
    "# =============================================================\n",
    "# 8. Save and validate assignments\n",
    "# =============================================================\n",
    "assign_df = pd.DataFrame(assign_rows)\n",
    "assign_df.to_csv(OUTPUT_ASSIGNMENTS, index=False)\n",
    "print(f\"Saved residue assignments to: {OUTPUT_ASSIGNMENTS}\")\n",
    "\n",
    "mask_assigned = assign_df[\"Status\"] == \"assigned\"\n",
    "reuse = (\n",
    "    assign_df[mask_assigned]\n",
    "    .groupby([\"Protein\", \"Residue Number\"])['Target Residue Number']\n",
    "    .nunique()\n",
    ")\n",
    "reuse = reuse[reuse > 1]\n",
    "if not reuse.empty:\n",
    "    print(\"WARNING: some residues were reused across targets:\")\n",
    "    print(reuse)\n",
    "\n",
    "# =============================================================\n",
    "# 9. Grouping (regex) + immediate summary printout\n",
    "# =============================================================\n",
    "if GROUP_MODE == 'all':\n",
    "    assign_df['Group'] = 'All'\n",
    "else:\n",
    "    def _extract_group(protein_id: str) -> str:\n",
    "        m = re.match(GROUP_REGEX, protein_id)\n",
    "        if m:\n",
    "            token = m.group(1)\n",
    "            return REGEX_MAP.get(token, token)\n",
    "        return 'Unassigned'\n",
    "    assign_df['Group'] = assign_df['Protein'].apply(_extract_group)\n",
    "\n",
    "print(\"\\n=== Group Summary ===\")\n",
    "present_groups = [g for g in sorted(assign_df['Group'].dropna().unique().tolist()) if g != 'Unassigned']\n",
    "if GROUP_MODE == 'all':\n",
    "    print(\"Running in 'all' mode: single group 'All'.\")\n",
    "else:\n",
    "    if not present_groups:\n",
    "        print(\"No valid groups found (all proteins Unassigned).\")\n",
    "    else:\n",
    "        print(f\"Total groups detected: {len(present_groups)}\")\n",
    "        for g in present_groups:\n",
    "            members = sorted(assign_df.loc[assign_df['Group'] == g, 'Protein'].unique().tolist())\n",
    "            print(f\"\\nGroup: {g}  (n={len(members)})\")\n",
    "            for m in members:\n",
    "                print(f\"  - {m}\")\n",
    "\n",
    "if EXPECTED_N_GROUPS is not None and GROUP_MODE == 'grouped':\n",
    "    n_found = len(present_groups)\n",
    "    assert n_found == EXPECTED_N_GROUPS, f\"Expected {EXPECTED_N_GROUPS} groups, found {n_found}: {present_groups}\"\n",
    "\n",
    "# =============================================================\n",
    "# 10. Frequency computation \n",
    "# =============================================================\n",
    "freq_rows = []\n",
    "use_groups = (present_groups if GROUP_MODE == 'grouped' else ['All'])\n",
    "\n",
    "for group in use_groups:\n",
    "    gdf = assign_df[assign_df['Group'] == group] if GROUP_MODE == 'grouped' else assign_df.copy()\n",
    "    for pos in TARGET_POSITIONS:\n",
    "        sdf = gdf[gdf['Target Residue Number'] == pos]\n",
    "        counts = sdf['Residue Name'].value_counts(normalize=True)\n",
    "        for aa, fr in counts.items():\n",
    "            freq_rows.append({\n",
    "                \"Group\": group,\n",
    "                \"Residue Position\": pos,\n",
    "                \"Residue Name\": aa,\n",
    "                \"Frequency\": fr,\n",
    "            })\n",
    "\n",
    "freq_df = pd.DataFrame(freq_rows)\n",
    "if freq_df.empty:\n",
    "    raise SystemExit(\"No frequency data computed. Check grouping or targets and inputs.\")\n",
    "\n",
    "# Reindex positions for plotting (helpers used later)\n",
    "unique_positions = freq_df[\"Residue Position\"].unique()\n",
    "position_mapping = {pos: idx for idx, pos in enumerate(sorted(unique_positions))}\n",
    "reverse_position_mapping = {v: k for k, v in position_mapping.items()}\n",
    "freq_df[\"Reindexed Position\"] = freq_df[\"Residue Position\"].map(position_mapping)\n",
    "\n",
    "# =============================================================\n",
    "# 11. Δ-frequency summary per position (dynamic group labels)\n",
    "# =============================================================\n",
    "if GROUP_MODE == 'grouped':\n",
    "    # Respect GROUP_SPEC order for readability\n",
    "    present_labels_in_order = [name for _, name in GROUP_SPEC if name in present_groups]\n",
    "    if len(present_labels_in_order) != 2:\n",
    "        raise SystemExit(\n",
    "            f\"Δ-frequency summary expects exactly 2 groups in grouped mode. Found {present_labels_in_order}.\"\n",
    "            \" Edit GROUP_SPEC or switch GROUP_MODE='all'.\"\n",
    "        )\n",
    "    G1_LABEL, G2_LABEL = present_labels_in_order\n",
    "\n",
    "    pivot = freq_df.pivot_table(\n",
    "        index=[\"Residue Position\", \"Residue Name\"],\n",
    "        columns=\"Group\",\n",
    "        values=\"Frequency\",\n",
    "        fill_value=0.0,\n",
    "    ).reset_index()\n",
    "\n",
    "    # Ensure both columns exist\n",
    "    for _col in [G1_LABEL, G2_LABEL]:\n",
    "        if _col not in pivot.columns:\n",
    "            pivot[_col] = 0.0\n",
    "\n",
    "    pivot[\"delta_mag\"] = (pivot[G1_LABEL] - pivot[G2_LABEL]).abs()\n",
    "\n",
    "    # Map specified residues from the reference protein\n",
    "    spec_map = {pos: specified_residues.get(pos, \"\") for pos in sorted(set(freq_df[\"Residue Position\"]))}\n",
    "\n",
    "    rows = []\n",
    "    for pos in sorted(pivot[\"Residue Position\"].dropna().astype(int).unique()):\n",
    "        sub = pivot[pivot[\"Residue Position\"] == pos].copy()\n",
    "        # exclude '-' and keep residues present in either group above cutoff\n",
    "        sub = sub[(sub[\"Residue Name\"] != \"-\") &\n",
    "                  ((sub[G1_LABEL] >= FREQ_CUTOFF) | (sub[G2_LABEL] >= FREQ_CUTOFF))]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        def _fmt_group(df, col):\n",
    "            s2 = df[df[col] >= FREQ_CUTOFF].copy().sort_values([col, \"Residue Name\"], ascending=[False, True])\n",
    "            return \", \".join(f\"{r}:{v:.2f}\" for r, v in zip(s2[\"Residue Name\"], s2[col]))\n",
    "\n",
    "        def _fmt_delta(df, col):\n",
    "            s2 = df[df[col] >= FREQ_CUTOFF].copy()\n",
    "            s2 = s2.sort_values([\"delta_mag\", col, \"Residue Name\"], ascending=[False, False, True])\n",
    "            return \", \".join(f\"{r}:{DELTA}{d:.2f}\" for r, d in zip(s2[\"Residue Name\"], s2[\"delta_mag\"]))\n",
    "\n",
    "        rows.append({\n",
    "            \"Residue Position\": int(pos),\n",
    "            G1_LABEL: _fmt_group(sub, G1_LABEL),\n",
    "            f\"{DELTA} {G1_LABEL.split()[0]}\": _fmt_delta(sub, G1_LABEL),\n",
    "            G2_LABEL: _fmt_group(sub, G2_LABEL),\n",
    "            f\"{DELTA} {G2_LABEL.split()[0]}\": _fmt_delta(sub, G2_LABEL),\n",
    "            \"Specified Residue\": spec_map.get(pos, \"\"),\n",
    "        })\n",
    "\n",
    "    summary_table = pd.DataFrame(rows).sort_values(\"Residue Position\")\n",
    "\n",
    "    # Save + show delta summary\n",
    "    summary_table.to_csv(DELTA_SUMMARY_OUT, index=False)\n",
    "    print(f\"\\nPer-position group deltas (freq >= {FREQ_CUTOFF:.2f}) saved to {DELTA_SUMMARY_OUT}\")\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(summary_table)\n",
    "    except Exception:\n",
    "        print(summary_table.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nSkipping Δ-frequency summary because GROUP_MODE='all'.\")\n",
    "\n",
    "# =============================================================\n",
    "# 12. Readable, chunked sequence logos (titles show only group name)\n",
    "# =============================================================\n",
    "valid_letters = set(AA3_TO_1.values())\n",
    "_groups_for_plot = use_groups\n",
    "\n",
    "for group in _groups_for_plot:\n",
    "    gdf = freq_df[freq_df['Group'] == group].copy()\n",
    "    gp = gdf.pivot_table(index='Reindexed Position', columns='Residue Name', values='Frequency', fill_value=0.0)\n",
    "    aa_cols = [c for c in gp.columns if isinstance(c, str) and len(c) == 1 and c in valid_letters]\n",
    "    gp = gp[sorted(aa_cols)]\n",
    "    if gp.empty:\n",
    "        print(f\"[skip] No valid AA columns for group '{group}'.\")\n",
    "        continue\n",
    "\n",
    "    # Prune globally-rare letters for readability\n",
    "    global_max = gp.max(axis=0)\n",
    "    keep_cols = [c for c in gp.columns if global_max[c] >= MIN_GLOBAL_FREQ]\n",
    "    gp = gp[keep_cols] if keep_cols else gp\n",
    "\n",
    "    gp = gp.sort_index()\n",
    "    all_pos = gp.index.to_list()\n",
    "    chunks = [all_pos[i:i+MAX_POSITIONS_PER_FIG] for i in range(0, len(all_pos), MAX_POSITIONS_PER_FIG)]\n",
    "\n",
    "    for ci, chunk in enumerate(chunks, start=1):\n",
    "        window = gp.loc[chunk]\n",
    "        xticklabels = [reverse_position_mapping[i] for i in window.index]\n",
    "        window_seq = window.reset_index(drop=True)  # align glyphs to 0..n-1 for plotting only\n",
    "\n",
    "        # Compute figure size in cm, convert to inches for Matplotlib\n",
    "        fig_width_cm = max(BASE_WIDTH_CM, BASE_WIDTH_CM + WIDTH_PER_POS_CM * len(xticklabels))\n",
    "        fig_height_cm = FIG_HEIGHT_CM\n",
    "        fig, ax = plt.subplots(figsize=(fig_width_cm * CM_TO_IN, fig_height_cm * CM_TO_IN))\n",
    "\n",
    "        _ = logomaker.Logo(window_seq, ax=ax, color_scheme=LOGO_COLOR_SCHEME)\n",
    "\n",
    "        ax.set_xlim(-0.5, len(xticklabels) - 0.5)\n",
    "        ax.set_xlabel('Residue Position', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('Frequency', fontsize=14, fontweight='bold')\n",
    "        ax.set_yticks(np.arange(0, 1.01, 0.2))\n",
    "        ax.set_yticklabels([f\"{t:.1f}\" for t in np.arange(0, 1.01, 0.2)], fontsize=11, fontweight='bold')\n",
    "        ax.set_xticks(range(len(xticklabels)))\n",
    "        ax.set_xticklabels(xticklabels, rotation=XTICK_LABEL_ROT, fontsize=10, fontweight='bold')\n",
    "        for s in ax.spines.values():\n",
    "            s.set_linewidth(1.2)\n",
    "\n",
    "        # Title now only shows the group name (e.g., \"Linear\" or \"Cyclical\")\n",
    "        ax.set_title(group, fontsize=16, pad=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if SAVE_LOGO_PNG:\n",
    "            safe_group = re.sub(r\"[^A-Za-z0-9_\\-]+\", \"_\", group).lower()\n",
    "            first_label, last_label = xticklabels[0], xticklabels[-1]\n",
    "            out_png = os.path.join(\n",
    "                OUTPUT_DIR,\n",
    "                f\"{safe_group}_logo_chunk{ci}_pos{first_label}-{last_label}.png\"\n",
    "            )\n",
    "            plt.savefig(out_png, dpi=DPI, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "# =============================================================\n",
    "# 13. Per-protein summary output\n",
    "# =============================================================\n",
    "try:\n",
    "    from IPython.display import display as _display\n",
    "except Exception:\n",
    "    _display = None\n",
    "\n",
    "_df = assign_df.copy()\n",
    "_df['Target Residue Number'] = pd.to_numeric(_df['Target Residue Number'], errors='coerce')\n",
    "_df['Residue Number'] = pd.to_numeric(_df['Residue Number'].where(_df['Residue Number'] != '-', np.nan), errors='coerce')\n",
    "\n",
    "for pid in sorted(_df['Protein'].unique()):\n",
    "    sub = _df[_df['Protein'] == pid].copy()\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"Protein: {pid} (rows={len(sub)})\")\n",
    "    cols = ['Target Residue Number', 'Target Residue Name', 'Residue Name', 'Residue Number', 'Distance', 'Status']\n",
    "    out = sub.sort_values(['Target Residue Number'])[cols]\n",
    "    if _display:\n",
    "        _display(out)\n",
    "    else:\n",
    "        print(out.to_string(index=False))\n",
    "\n",
    "# =============================================================\n",
    "# 14. Completion message\n",
    "# =============================================================\n",
    "print(\"\\nScript completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
